import streamlit as st
from dotenv import find_dotenv, load_dotenv
from langchain_core.prompts import ChatPromptTemplate
from langchain_groq import ChatGroq
models = {
    "gemma-7b-it": {"name": "Gemma-7b-it", "tokens": 8192, "developer": "Google"},
    "llama2-70b-4096": {"name": "LLaMA2-70b-chat", "tokens": 4096, "developer": "Meta"},
    "llama3-70b-8192": {"name": "LLaMA3-70b-8192", "tokens": 8192, "developer": "Meta"},
    "llama3-8b-8192": {"name": "LLaMA3-8b-8192", "tokens": 8192, "developer": "Meta"},
    "mixtral-8x7b-32768": {"name": "Mixtral-8x7b-Instruct-v0.1", "tokens": 32768, "developer": "Mistral"},
}

def load_model(question,model_option):
    load_dotenv(find_dotenv())  # Load the .env file.
    chat = ChatGroq(temperature=0, model_name=model_option)
    system = "You are a helpful assistant."
    human = "{text}"
    prompt = ChatPromptTemplate.from_messages([("system", system), ("human", human)])
    chain = prompt | chat
    result=chain.invoke({"text":question })
    return result.content

if __name__ == "__main__":
    #é¡µé¢ç»˜åˆ¶
    st.header("ChatBot-AIæœºå™¨äºº", divider="rainbow", anchor=False)
    # st.caption("ğŸš€ A streamlit website based by GroqCloud")

    #åˆå§‹åŒ–æ¨¡å‹é€‰æ‹©
    if "selected_model" not in st.session_state:
        st.session_state.selected_model = None

    # åˆå§‹åŒ–èŠå¤©è®°å½•
    if "messages" not in st.session_state:#åˆå§‹åŒ–èŠå¤©è®°å½•
        st.session_state["messages"] = list()

    with st.sidebar:
        #æ¨¡å‹é€‰æ‹©
        model_option = st.selectbox(
        "Choose a model:",
        options=list(models.keys()),
        format_func=lambda x: models[x]["name"],
        index=0  # Default to mixtral
        )
        #æ¸…é™¤èŠå¤©è®°å½•
        st.button("Clear Chat History", on_click=lambda: st.session_state.pop("messages", None))
        st.text("Gemmaé€‚åˆä¸­æ–‡è¯­å¢ƒ")
        st.text("LLaMA2-70bæ€§èƒ½å‡è¡¡")
        st.text("LLaMA3-70bç²¾å‡†åº¦é«˜")
        st.text("LLaMA3-8bé€Ÿåº¦å¿«")
        st.text("Mixtralé€Ÿåº¦å¿«ï¼Œé€‚åˆé•¿æ–‡æœ¬")
    
    st.chat_message("assistant").write("ä½ å¥½ï¼Œæˆ‘æ˜¯åŸºäºå¤§æ¨¡å‹çš„AIå¯¹è¯æœºå™¨äººï¼Œè¯·è¾“å…¥ä½ æƒ³è¯¢é—®çš„é—®é¢˜")
    # if "messages" not in st.session_state:
        # st.session_state["messages"] = [
        #     {"role": "assistant", "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯åŸºäºå¤§æ¨¡å‹çš„AIå¯¹è¯æœºå™¨äººï¼Œè¯·è¾“å…¥ä½ æƒ³è¯¢é—®çš„é—®é¢˜"}
        # ]
    #æ˜¾ç¤ºå¯¹è¯è¿‡ç¨‹
    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    #è¾“å…¥é—®é¢˜
    question = st.chat_input()
    if question:
    # print(question)
        st.session_state.messages.append({"role": "user", "content": question})
        st.chat_message("user").write(question)
        response = load_model(question,model_option)
        st.session_state.messages.append({"role": "assistant", "content": response})
        st.chat_message("assistant").write(response)

    


  