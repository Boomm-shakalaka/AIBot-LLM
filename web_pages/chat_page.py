import random
import streamlit as st
from langchain_core.messages import AIMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_groq import ChatGroq
from langchain_community.chat_models import QianfanChatEndpoint
from config_setting import model_config,prompt_config
from langchain_google_genai import ChatGoogleGenerativeAI
from dotenv import find_dotenv, load_dotenv

class chatbot:
    def __init__(self):
        load_dotenv(find_dotenv())#åŠ è½½ç¯å¢ƒå˜é‡
        self.model_option = None
        self.model_tokens = None
        self.llm = None

    def get_response(self,question,chat_history):
        try:
            if self.model_option =='ERNIE-Lite-8K' or self.model_option=='ERNIE-speed-128k': #é€‰æ‹©ç™¾åº¦åƒå¸†å¤§æ¨¡å‹
                self.llm = QianfanChatEndpoint(model=self.model_option)
            elif self.model_option == 'gemini-1.5-flash-latest': #é€‰æ‹©è°·æ­ŒGemmaå¤§æ¨¡å‹,ä¸æ”¯æŒæµå¼è¾“å‡ºæš‚æœªä½¿ç”¨
                model_choice=random.choice(["gemini-1.5-flash-latest",'gemini-1.0-pro-001','gemini-1.5-pro-latest',"gemini-1.0-pro"])
                self.llm = ChatGoogleGenerativeAI(model=model_choice,temperature=0.7)#ChatGoogleGenerativeAIæ¨¡å‹
            else:
                self.llm = ChatGroq(model_name=self.model_option,temperature=0.5,max_tokens=self.model_tokens)#ChatGroqæ¨¡å‹
            prompt = ChatPromptTemplate.from_template(prompt_config.chatbot_prompt)
            chain = prompt | self.llm | StrOutputParser()
            # result=chain.invoke({"chat_history": chat_history,"question": question,}) #éæµå¼è¾“å‡º
            # return result
            return chain.stream({
                "chat_history": chat_history,
                "question": question,
            })
        except Exception as e:
            return f"å½“å‰æ¨¡å‹{self.model_option}æš‚ä¸å¯ç”¨ï¼Œè¯·åœ¨å·¦ä¾§æ é€‰æ‹©å…¶ä»–æ¨¡å‹ã€‚"
        
def init_params():
    if "chat_message" not in st.session_state:
        st.session_state.chat_message = []
    if "chat_bot" not in st.session_state:
        st.session_state.chat_bot = chatbot()
        
#æ¸…é™¤èŠå¤©è®°å½•
def clear():
    st.session_state.chat_message = [] #æ¸…é™¤èŠå¤©è®°å½•
    st.session_state.chat_bot = chatbot() #é‡æ–°åˆå§‹åŒ–æ¨¡å‹

    
def chat_page():
    init_params()#åˆå§‹åŒ–æ¨¡å‹å’ŒèŠå¤©è®°å½•
    '''é¡µé¢å¸ƒå±€'''    
    with st.sidebar:
        with st.container(border=True):
            select_model=st.selectbox("é€‰æ‹©æ¨¡å‹",options=["ç™¾åº¦åƒå¸†å¤§æ¨¡å‹-8k","ç™¾åº¦åƒå¸†å¤§æ¨¡å‹-128k","è°·æ­ŒGemmaå¤§æ¨¡å‹","Llama3-70bå¤§æ¨¡å‹","Llama3-8bå¤§æ¨¡å‹","Mixtralå¤§æ¨¡å‹"],index=0)#æ¨¡å‹é€‰æ‹©
            model_option=model_config.model_ls[select_model]["name"]#æ¨¡å‹åç§°
            model_tokes=model_config.model_ls[select_model]["tokens"]#æ¨¡å‹tokens
            st.button(label="æ¸…é™¤èŠå¤©è®°å½•", on_click=lambda: clear(),use_container_width=True) #æ¸…é™¤èŠå¤©è®°å½•æŒ‰é’®
    st.title("ğŸ’¬ AIèŠå¤©æœºå™¨äºº")
    st.subheader(body='',divider="rainbow")

    '''æ»šåŠ¨æ›´æ–°èŠå¤©è®°å½•'''
    with st.chat_message("AI"):
        st.markdown("æ‚¨å¥½ï¼Œæˆ‘æ˜¯AIèŠå¤©æœºå™¨äººï¼Œæˆ‘ä¼šå°½åŠ›å›ç­”æ‚¨çš„é—®é¢˜ã€‚æ­¤å¤–åœ¨æˆ‘çš„å·¦ä¾§æ ä¸­ï¼Œæ‚¨å¯ä»¥æ›´æ¢ä¸åŒçš„AIæ¨¡å‹ã€‚")
    for message in st.session_state.chat_message:
        if isinstance(message, AIMessage):
            with st.chat_message("AI"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("Human"):
                st.markdown(message.content)

    '''ç”¨æˆ·é—®é¢˜äº¤äº’'''
    question = st.chat_input("è¾“å…¥ä½ çš„é—®é¢˜")
    if question:
        st.session_state.chat_bot.model_option = model_option
        st.session_state.chat_bot.model_tokens = model_tokes
        with st.chat_message("Human"):
            st.markdown(question)
            st.session_state.chat_message.append(HumanMessage(content=question))#æ·»åŠ ç”¨æˆ·é—®é¢˜èŠå¤©è®°å½•
        with st.chat_message("AI"):
            response = st.write_stream(st.session_state.chat_bot.get_response(question,st.session_state.chat_message)) #æµå¼è¾“å‡ºï¼Œæ‰€ä»¥ä¸ç”¨markdown
            st.session_state.chat_message.append(AIMessage(content=response))#æ·»åŠ ç”¨æˆ·é—®é¢˜èŠå¤©è®°å½•
